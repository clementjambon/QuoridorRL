%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Nathan Pollet at 2022-03-01 9:55:22 AM +0100 


%% Saved with string encoding Unicode (UTF-8) 

%@article{MCTS-RAVE,
%	date-added = {2022-02-28 9:02:16 PM +0100},
%	author = {Sylvain Gelly and David Silver},
%	date-modified = {2022-02-28 9:02:16 PM +0100},
%	doi = {https://doi.org/10.1016/j.artint.2011.03.007},
%	issn = {0004-3702},
%	journal = {Artificial Intelligence},
%	keywords = {Computer Go, Monte-Carlo, Search, Reinforcement learning},
%	number = {11},
%	pages = {1856-1875},
%	title = {Monte-Carlo tree search and rapid action value estimation in computer Go},
%	url = {https://www.sciencedirect.com/science/article/pii/S000437021100052X},
%	volume = {175},
%	year = {2011},
%	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S000437021100052X},
%	Bdsk-Url-2 = {https://doi.org/10.1016/j.artint.2011.03.007}}

@article{GELLY20111856,
title = {Monte-Carlo tree search and rapid action value estimation in computer Go},
journal = {Artificial Intelligence},
volume = {175},
number = {11},
pages = {1856-1875},
year = {2011},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2011.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S000437021100052X},
author = {Sylvain Gelly and David Silver},
keywords = {Computer Go, Monte-Carlo, Search, Reinforcement learning},
abstract = {A new paradigm for search, based on Monte-Carlo simulation, has revolutionised the performance of computer Go programs. In this article we describe two extensions to the Monte-Carlo tree search algorithm, which significantly improve the effectiveness of the basic algorithm. When we applied these two extensions to the Go program MoGo, it became the first program to achieve dan (master) level in 9Ã—9 Go. In this article we survey the Monte-Carlo revolution in computer Go, outline the key ideas that led to the success of MoGo and subsequent Go programs, and provide for the first time a comprehensive description, in theory and in practice, of this extended framework for Monte-Carlo tree search.}
}

@misc{quoridor-gigamic,
	author = {Gigamic Games},
	date-added = {2022-02-28 6:40:28 PM +0100},
	date-modified = {2022-02-28 6:41:39 PM +0100},
	howpublished = {Gigamic Games, \url{https://en.gigamic.com/game/quoridor}},
	title = {Quoridor},
	year = {1997}}

@article{alphago,
	added-at = {2016-03-11T14:36:05.000+0100},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/ytyoun},
	doi = {10.1038/nature16961},
	interhash = {48430c7891aaf9fe2582faa8f5d076c1},
	intrahash = {9e987f58d895c490144693139cbc90c7},
	journal = {Nature},
	keywords = {baduk go google},
	month = jan,
	number = 7587,
	pages = {484--489},
	publisher = {Nature Publishing Group},
	timestamp = {2016-03-11T14:37:40.000+0100},
	title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
	volume = 529,
	year = 2016,
	Bdsk-Url-1 = {https://doi.org/10.1038/nature16961}}

@article{alphagozero,
	added-at = {2017-12-15T02:14:58.000+0100},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	biburl = {https://www.bibsonomy.org/bibtex/2ecdfbfcceb55ee5f14c1c375ad71f2cb/achakraborty},
	description = {Mastering the game of Go without human knowledge | Nature},
	interhash = {c45d318e105d0f2d62ccc28c2699d9d4},
	intrahash = {ecdfbfcceb55ee5f14c1c375ad71f2cb},
	journal = {Nature},
	keywords = {2017 deep-learning deepmind google paper reinforcement-learning},
	month = oct,
	pages = {354--},
	publisher = {Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	timestamp = {2017-12-15T02:14:58.000+0100},
	title = {Mastering the game of Go without human knowledge},
	url = {http://dx.doi.org/10.1038/nature24270},
	volume = 550,
	year = 2017,
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nature24270}}

@article{alphazero,
	abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system. Science, this issue p. 1140; see also pp. 1087 and 1118 AlphaZero teaches itself to play three different board games and beats state-of-the-art programs in each. The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	author = {David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
	doi = {10.1126/science.aar6404},
	eprint = {https://www.science.org/doi/pdf/10.1126/science.aar6404},
	journal = {Science},
	number = {6419},
	pages = {1140-1144},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	url = {https://www.science.org/doi/abs/10.1126/science.aar6404},
	volume = {362},
	year = {2018},
	Bdsk-Url-1 = {https://www.science.org/doi/abs/10.1126/science.aar6404},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.aar6404}}

@article{mcts-review,
	author = {Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
	doi = {10.1109/TCIAIG.2012.2186810},
	journal = {IEEE Transactions on Computational Intelligence and AI in Games},
	number = {1},
	pages = {1-43},
	title = {A Survey of Monte Carlo Tree Search Methods},
	volume = {4},
	year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1109/TCIAIG.2012.2186810}}

@misc{pygame,
	author = {Pete Shinners},
	howpublished = {\url{http://pygame.org/}},
	title = {PyGame},
	year = {2011}}

@article{mc-rave,
	author = {Sylvain Gelly and David Silver},
	doi = {https://doi.org/10.1016/j.artint.2011.03.007},
	issn = {0004-3702},
	journal = {Artificial Intelligence},
	keywords = {Computer Go, Monte-Carlo, Search, Reinforcement learning},
	number = {11},
	pages = {1856-1875},
	title = {Monte-Carlo tree search and rapid action value estimation in computer Go},
	url = {https://www.sciencedirect.com/science/article/pii/S000437021100052X},
	volume = {175},
	year = {2011},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S000437021100052X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.artint.2011.03.007}}

@inproceedings{heuristic-agent,
	author = {P. J. C. Mertens},
	title = {A Quoridor-playing Agent},
	year = {2006}}

@inproceedings{mastering-quoridor,
	author = {Glendenning, Lisa},
	title = {Mastering Quoridor},
	year = {2005}}

@misc{quoridor-wikipedia,
	author = {Wikipedia},
	howpublished = {\url{https://en.wikipedia.org/wiki/Quoridor}},
	note = {[Online; accessed 28 February 2022]},
	title = {Quoridor},
	year = {2022}}

@book{russel2010,
	added-at = {2020-02-01T18:23:11.000+0100},
	author = {Russell, Stuart and Norvig, Peter},
	biburl = {https://www.bibsonomy.org/bibtex/20533b732950d1c5ab4ac12d4f32fe637/mialhoma},
	chapter = {3},
	edition = 3,
	interhash = {53908a52dd4c6c8e39f93f4ffc8341be},
	intrahash = {0533b732950d1c5ab4ac12d4f32fe637},
	keywords = {ties4530},
	publisher = {Prentice Hall},
	timestamp = {2020-02-01T18:23:11.000+0100},
	title = {Artificial Intelligence: A Modern Approach},
	year = 2010}

@misc{openai-gym,
	author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
	eprint = {arXiv:1606.01540},
	title = {OpenAI Gym},
	year = {2016}}

@incollection{pytorch,
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {8024--8035},
	publisher = {Curran Associates, Inc.},
	title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
	year = {2019},
	Bdsk-Url-1 = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}}

@article{muzero,
	author = {Julian Schrittwieser and Ioannis Antonoglou and Thomas Hubert and Karen Simonyan and L. Sifre and Simon Schmitt and Arthur Guez and Edward Lockhart and Demis Hassabis and Thore Graepel and Timothy P. Lillicrap and David Silver},
	journal = {Nature},
	pages = {604-609},
	title = {Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model},
	volume = {588 7839},
	year = {2020}}

@article{gdl,
	author = {Michael M. Bronstein and Joan Bruna and Taco Cohen and Petar Velickovic},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2104-13478.bib},
	eprint = {2104.13478},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Tue, 04 May 2021 15:12:43 +0200},
	title = {Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges},
	url = {https://arxiv.org/abs/2104.13478},
	volume = {abs/2104.13478},
	year = {2021},
	Bdsk-Url-1 = {https://arxiv.org/abs/2104.13478}}

@inproceedings{dilated-conv,
	author = {Fisher Yu and Vladlen Koltun},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/YuK15.bib},
	booktitle = {4th International Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
	editor = {Yoshua Bengio and Yann LeCun},
	timestamp = {Thu, 25 Jul 2019 14:25:38 +0200},
	title = {Multi-Scale Context Aggregation by Dilated Convolutions},
	url = {http://arxiv.org/abs/1511.07122},
	year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1511.07122}}
